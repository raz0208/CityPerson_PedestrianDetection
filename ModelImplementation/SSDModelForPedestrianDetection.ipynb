{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsVu0106AQ8wiPpxWMbhtg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raz0208/CityPerson_PedestrianDetection/blob/main/ModelImplementation/SSDModelForPedestrianDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSjPaDyi1V5N"
      },
      "outputs": [],
      "source": [
        "# Instal Required Libraries\n",
        "import os\n",
        "import json\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models.detection as detection\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_tif_to_jpg(source_dir, target_dir):\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "    for root, _, files in os.walk(source_dir):\n",
        "        for file in files:\n",
        "            if file.endswith('.tif'):\n",
        "                tif_path = os.path.join(root, file)\n",
        "                img = Image.open(tif_path).convert('L')  # Convert to grayscale if not already\n",
        "                jpg_file = file.replace('.tif', '.jpg')\n",
        "                target_path = os.path.join(target_dir, jpg_file)\n",
        "                img.save(target_path, 'JPEG')\n",
        "                #print(f\"Converted {tif_path} to {target_path}\")"
      ],
      "metadata": {
        "id": "5N-_js3w14oB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from the source and store the result in new path\n",
        "source_folder = '/kaggle/input/city-persone/gtFinePanopticParts_trainval/gtFinePanopticParts/train'\n",
        "destination_folder = '/kaggle/working/CityPersonBboxPanoptic/train/images'\n",
        "convert_tif_to_jpg(source_folder, destination_folder)\n",
        "\n",
        "# Read the data from the source and store the result in new path\n",
        "source_folder = '/kaggle/input/city-persone/gtFinePanopticParts_trainval/gtFinePanopticParts/val'\n",
        "destination_folder = '/kaggle/working/CityPersonBboxPanoptic/val/images'\n",
        "convert_tif_to_jpg(source_folder, destination_folder)"
      ],
      "metadata": {
        "id": "Eae6ZQ8K8f6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_json_to_txt(source_dir, target_dir):\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "    for root, _, files in os.walk(source_dir):\n",
        "        for file in files:\n",
        "            if file.endswith('.json'):\n",
        "                json_path = os.path.join(root, file)\n",
        "                with open(json_path, 'r') as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                txt_file = file.replace('.json', '.txt')\n",
        "                target_path = os.path.join(target_dir, txt_file)\n",
        "\n",
        "                with open(target_path, 'w') as f:\n",
        "                    for obj in data.get('objects', []):\n",
        "                        label = obj.get('label', 'unknown')\n",
        "                        x, y, w, h = obj.get('bbox', [0, 0, 0, 0])\n",
        "                        f.write(f\"{label} {x} {y} {w} {h}\\n\")\n",
        "\n",
        "                #print(f\"Converted {json_path} to {target_path}\")"
      ],
      "metadata": {
        "id": "zf2OG9368jWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from the source and store the result in new path\n",
        "source_folder = '/kaggle/input/city-persone/gtBbox_cityPersons_trainval/gtBboxCityPersons/train'\n",
        "destination_folder = '/kaggle/working/CityPersonBboxPanoptic/train/labels'\n",
        "convert_json_to_txt(source_folder, destination_folder)\n",
        "\n",
        "# Read the data from the source and store the result in new path\n",
        "source_folder = '/kaggle/input/city-persone/gtBbox_cityPersons_trainval/gtBboxCityPersons/val'\n",
        "destination_folder = '/kaggle/working/CityPersonBboxPanoptic/val/labels'\n",
        "convert_json_to_txt(source_folder, destination_folder)"
      ],
      "metadata": {
        "id": "THGdPHzc8lEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define label mapping for SSD\n",
        "class_mapping = {\n",
        "    \"pedestrian\": 0,\n",
        "    \"rider\": 1,\n",
        "    \"sitting person\": 2,\n",
        "    \"person group\": 3,\n",
        "    \"person (other)\": 4,\n",
        "}\n",
        "\n",
        "def convert_txt_to_ssd_format(source_dir, target_dir):\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "    for root, _, files in os.walk(source_dir):\n",
        "        for file in files:\n",
        "            if file.endswith('.txt'):\n",
        "                txt_path = os.path.join(root, file)\n",
        "                target_path = os.path.join(target_dir, file)\n",
        "\n",
        "                with open(txt_path, 'r') as f:\n",
        "                    lines = f.readlines()\n",
        "\n",
        "                with open(target_path, 'w') as f:\n",
        "                    for line in lines:\n",
        "                        parts = line.strip().split()\n",
        "                        if len(parts) == 7:\n",
        "                            label, x, y, w, h, img_width, img_height = parts\n",
        "                            label_id = class_mapping.get(label, -1)\n",
        "                            if label_id == -1:\n",
        "                                continue\n",
        "                            x, y, w, h, img_width, img_height = map(int, [x, y, w, h, img_width, img_height])\n",
        "                            x_min = x / img_width\n",
        "                            y_min = y / img_height\n",
        "                            x_max = (x + w) / img_width\n",
        "                            y_max = (y + h) / img_height\n",
        "                            f.write(f\"{label_id} {x_min:.6f} {y_min:.6f} {x_max:.6f} {y_max:.6f}\\n\")\n",
        "\n",
        "                #print(f\"Converted {txt_path} to SSD format at {target_path}\")"
      ],
      "metadata": {
        "id": "68L4HR44Mki5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from the source and store the result in new path\n",
        "source_folder = '/kaggle/working/CityPersonBboxPanoptic/train/labels'\n",
        "destination_folder = '/kaggle/working/CityPersonBboxSSDFormat/train/labels'\n",
        "convert_txt_to_ssd_format(source_folder, destination_folder)\n",
        "\n",
        "# Read the data from the source and store the result in new path\n",
        "source_folder = '/kaggle/working/CityPersonBboxPanoptic/train/labels'\n",
        "destination_folder = '/kaggle/working/CityPersonBboxSSDFormat/val/labels'\n",
        "convert_txt_to_ssd_format(source_folder, destination_folder)"
      ],
      "metadata": {
        "id": "azS9ifw1Mtkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rename_files_in_dir(output_dir):\n",
        "    \"\"\"\n",
        "    Rename all .txt files in the output_dir by replacing 'gtBboxCityPersons' with 'gtFinePanopticParts'.\n",
        "    \"\"\"\n",
        "    # Loop through all files in the directory\n",
        "    for file_name in os.listdir(output_dir):\n",
        "        # Check if the file is a .txt file\n",
        "        if file_name.endswith('.txt'):\n",
        "            # Replace 'gtBboxCityPersons' with 'gtFinePanopticParts' in the file name\n",
        "            new_name = file_name.replace('gtBboxCityPersons.ssd', 'gtFinePanopticParts')\n",
        "\n",
        "            # Get the full path of the old and new file names\n",
        "            old_file_path = os.path.join(output_dir, file_name)\n",
        "            new_file_path = os.path.join(output_dir, new_name)\n",
        "\n",
        "            if os.path.exists(new_file_path):\n",
        "                print(f\"Skipping rename: {new_file_path} already exists\")\n",
        "            else:\n",
        "                # Rename the file\n",
        "                os.rename(old_file_path, new_file_path)\n",
        "\n",
        "# Define the output directory where the text files are located\n",
        "output_dir = '/kaggle/working/CityPersonBboxSSDFormat/train/labels'\n",
        "output_dir1 = '/kaggle/working/CityPersonBboxSSDFormat/val/labels'\n",
        "\n",
        "# Rename all .txt files in the directory\n",
        "rename_files_in_dir(output_dir)\n",
        "rename_files_in_dir(output_dir1)"
      ],
      "metadata": {
        "id": "T-w3HrfS_kJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_empty_files(txt_dir, img_dir):\n",
        "    txt_rm_files = 0\n",
        "    jpg_rm_files = 0\n",
        "    for root, _, files in os.walk(txt_dir):\n",
        "        for file in files:\n",
        "            if file.endswith('.txt'):\n",
        "                txt_path = os.path.join(root, file)\n",
        "                if os.path.getsize(txt_path) == 0:\n",
        "                    os.remove(txt_path)\n",
        "                    txt_rm_files += 1\n",
        "                    #print(f\"Removed empty file: {txt_path}\")\n",
        "                    jpg_file = file.replace('.txt', '.jpg')\n",
        "                    jpg_path = os.path.join(img_dir, jpg_file)\n",
        "                    if os.path.exists(jpg_path):\n",
        "                        os.remove(jpg_path)\n",
        "                        jpg_rm_files += 1\n",
        "                        #print(f\"Removed corresponding image: {jpg_path}\")\n",
        "    print(f\"txt file romeved count: {txt_rm_files}\")\n",
        "    print(f\"jpg file romeved count: {jpg_rm_files}\")"
      ],
      "metadata": {
        "id": "X9U7-p1y_lzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from train set\n",
        "source_txt_files = '/kaggle/working/CityPersonBboxSSDFormat/train/labels'\n",
        "source_jpg_files = '/kaggle/working/CityPersonBboxPanoptic/train/images'\n",
        "print('Empty removed files from traning set (images and labels):')\n",
        "remove_empty_files(source_txt_files, source_jpg_files)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "# Read the data from train set\n",
        "source_txt_files = '/kaggle/working/CityPersonBboxSSDFormat/val/labels'\n",
        "source_jpg_files = '/kaggle/working/CityPersonBboxPanoptic/val/images'\n",
        "print('Empty removed files from val set (images and labels):')\n",
        "remove_empty_files(source_txt_files, source_jpg_files)"
      ],
      "metadata": {
        "id": "uW4Ozxkg_na4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_images(source_dir, target_dir, size=(512, 512)):\n",
        "    \"\"\"\n",
        "    Resize images to a specified size and save them to the target directory.\n",
        "\n",
        "    Args:\n",
        "        source_dir (str): Directory containing the original images.\n",
        "        target_dir (str): Directory to save the resized images.\n",
        "        size (tuple): Target size (width, height) for resizing.\n",
        "    \"\"\"\n",
        "    os.makedirs(target_dir, exist_ok=True)\n",
        "    for root, _, files in os.walk(source_dir):\n",
        "        for file in files:\n",
        "            if file.endswith('.jpg'):\n",
        "                img_path = os.path.join(root, file)\n",
        "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
        "\n",
        "                if img is not None:\n",
        "                    resized_img = cv2.resize(img, size)\n",
        "                    target_path = os.path.join(target_dir, file)\n",
        "                    cv2.imwrite(target_path, resized_img)\n",
        "                    #print(f\"Resized and saved: {target_path}\")\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "train_images_dir = '/kaggle/working/CityPersonBboxPanoptic/train/images'\n",
        "resized_train_dir = '/kaggle/working/CityPersonBboxSSDFormat/train/images'\n",
        "resize_images(train_images_dir, resized_train_dir, size=(512, 512))\n",
        "\n",
        "val_images_dir = '/kaggle/working/CityPersonBboxPanoptic/val/images'\n",
        "resized_val_dir = '/kaggle/working/CityPersonBboxSSDFormat/val/images'\n",
        "resize_images(val_images_dir, resized_val_dir, size=(512, 512))"
      ],
      "metadata": {
        "id": "0e0p9fms_o7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.models.detection import ssd300_vgg16\n",
        "\n",
        "class PedestrianDataset(Dataset):\n",
        "    def __init__(self, images_dir, labels_dir, transform=None):\n",
        "        self.images_dir = images_dir\n",
        "        self.labels_dir = labels_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = [f for f in os.listdir(images_dir) if f.endswith('.jpg')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.images_dir, self.image_files[idx])\n",
        "        label_path = os.path.join(self.labels_dir, self.image_files[idx].replace('.jpg', '.txt'))\n",
        "\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)  # Convert grayscale to 3 channels\n",
        "\n",
        "        h, w = img.shape[:2]\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        if os.path.exists(label_path):\n",
        "            with open(label_path, 'r') as f:\n",
        "                for line in f.readlines():\n",
        "                    parts = line.strip().split()\n",
        "                    label = int(parts[0])\n",
        "                    x_center, y_center, width, height = map(float, parts[1:])\n",
        "\n",
        "                    x_min = (x_center - width / 2) * w\n",
        "                    y_min = (y_center - height / 2) * h\n",
        "                    x_max = (x_center + width / 2) * w\n",
        "                    y_max = (y_center + height / 2) * h\n",
        "\n",
        "                    boxes.append([x_min, y_min, x_max, y_max])\n",
        "                    labels.append(label)\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "        target = {'boxes': boxes, 'labels': labels}\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "# Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((512, 512)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Dataset and DataLoader\n",
        "train_dataset = PedestrianDataset('/kaggle/working/CityPersonBboxSSDFormat/train/images',\n",
        "                                  '/kaggle/working/CityPersonBboxSSDFormat/train/labels',\n",
        "                                  transform=transform)\n",
        "\n",
        "val_dataset = PedestrianDataset('/kaggle/working/CityPersonBboxSSDFormat/val/images',\n",
        "                                '/kaggle/working/CityPersonBboxSSDFormat/val/labels',\n",
        "                                transform=transform)"
      ],
      "metadata": {
        "id": "s1RlsP6__qx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"
      ],
      "metadata": {
        "id": "lTnTQMxN_6UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SSD Model\n",
        "model = ssd300_vgg16(pretrained=True)\n",
        "num_classes = 5 + 1  # 5 classes + background\n",
        "model.head.classification_head.num_classes = num_classes\n",
        "\n",
        "# Training setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)"
      ],
      "metadata": {
        "id": "etLzSB47_75A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for images, targets in train_loader:\n",
        "        images = [img.to(device) for img in images]\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {losses.item():.4f}\")\n",
        "\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "id": "16PoDOJ3ALkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length of true_labels: {len(true_labels)}\")\n",
        "print(f\"Length of pred_labels: {len(pred_labels)}\")"
      ],
      "metadata": {
        "id": "BoQ7rc0IAVcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "# Define class names\n",
        "class_names = [\"pedestrian\", \"rider\", \"sitting person\", \"person group\", \"person (other)\"]\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ak-OFJxWAgOF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}